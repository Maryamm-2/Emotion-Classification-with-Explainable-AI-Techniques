# Emotion Classification with Explainable AI Techniques

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/maryam-haroon-ba51b8287/)

[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Machine Learning](https://img.shields.io/badge/Machine%20Learning-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![Deep Learning](https://img.shields.io/badge/Deep%20Learning-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Transformers](https://img.shields.io/badge/Transformers-81C14B?style=for-the-badge&logo=huggingface&logoColor=white)](https://huggingface.co/docs/transformers/index)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![NLP](https://img.shields.io/badge/NLP-Natural%20Language%20Processing-blue?style=for-the-badge)](https://en.wikipedia.org/wiki/Natural_language_processing)
[![Explainable AI](https://img.shields.io/badge/Explainable%20AI-XAI-orange?style=for-the-badge)](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)
[![Gemini API](https://img.shields.io/badge/Gemini%20API-8E75B2?style=for-the-badge&logo=google&logoColor=white)](https://ai.google.dev/)
[![GitHub](https://img.shields.io/badge/GitHub-Repo-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

> **Advanced Emotion Classification Pipeline Integrating Deep Learning, Transformers, and Explainable AI (XAI)**

This repository houses a sophisticated NLP system designed to classify human emotions from text with high accuracy while providing transparent, interpretability-focused explanations. By bridging the gap between "black box" deep learning models and human understanding, this project implements a hybrid architecture combining LSTM networks, DistilBERT transformers, and Large Language Models (LLMs) like Google Gemini and Flan-T5.

The system addresses the critical need for transparency in AI by rigorously applying post-hoc explainability techniquesâ€”SHAP (Shapley Additive exPlanations), LIME (Local Interpretable Model-agnostic Explanations), and Attention Rollout. It serves as a comprehensive reference for AI researchers and engineers working at the intersection of Natural Language Processing, Affective Computing, and Responsible AI.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 1. Skills & Technologies

### Languages & Frameworks
![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=flat-square&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10%2B-orange?style=flat-square&logo=tensorflow)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red?style=flat-square&logo=pytorch)
![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Transformers-yellow?style=flat-square&logo=huggingface)

### Machine Learning & Deep Learning
*   **Architectures**: Long Short-Term Memory (LSTM), DistilBERT (Transformers), Generative LLMs (Flan-T5, Gemini).
*   **Techniques**: Transfer Learning, Fine-tuning, Zero-shot & Few-shot Learning, Sequence Padding, Tokenization.

### Explainable AI (XAI)
*   **SHAP**: Game-theoretic feature importance (Partition Explainer).
*   **LIME**: Local surrogate models for perturbation-based explanation.
*   **Attention Mechanisms**: Visualization of Transformer attention heads and rollout.
*   **Generative Explanation**: Natural language reasoning using Seq2Seq models.

### Data Engineering & Tools
*   **Libraries**: Pandas, NumPy, Scikit-learn, Datasets (Hugging Face).
*   **APIs**: Google GenAI (Gemini 1.5 Flash).
*   **DevOps**: Git, Virtual Environments.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 2. Project Description

This project implements an end-to-end pipeline for **Emotion Recognition in Text**, classifying inputs into six core categories: *sadness, joy, love, anger, fear, and surprise*. 

Unlike traditional classifiers that output a simple label, this system prioritizes **interpretability**. It offers a multi-model approach where users can choose between lightweight LSTMs for efficiency or powerful Transformers for accuracy. Crucially, every prediction is accompanied by a "why"â€”visualized through attention heatmaps, SHAP force plots, or natural language explanations generated by a secondary LLM. This ensures adherence to Trustworthy AI principles, making the model's decision-making process transparent to stakeholders.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 3. Problem Statement

In safety-critical and user-centric domains like mental health monitoring and customer experience management, high accuracy is not enough. Deep Learning models, particularly Transformers, are often opaque "black boxes."
*   **The Trust Gap**: Users hesitate to trust AI decisions without understanding the underlying rationale.
*   **Bias detection**: Without visibility into feature importance, models may rely on spurious correlations.
*   **Regulatory Compliance**: Increasing regulations (e.g., EU AI Act) demand explainability for automated decision-making systems.

This project solves these issues by embedding explainability directly into the classification workflow.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 4. Solution Overview

The solution follows a modular strategy:

1.  **Data Ingest & Preprocessing**:
    *   Ingests the `dair-ai/emotion` dataset.
    *   Performs text normalization, cleaning, and subword tokenization.
    *   Applies padding for LSTM and attention masking for Transformers.

2.  **Modeling Strategies**:
    *   **Baseline**: LSTM with converting embedding layers.
    *   **SOTA**: Fine-tuned DistilBERT for context-aware classification.
    *   **Generative**: Zero-shot and Few-shot prompting with Gemini 1.5 Flash.

3.  **Explainability Layer**:
    *   **LIME**: Perturbs input text to find words robustly integrated with the predicted class.
    *   **SHAP**: Calculates the marginal contribution of each token to the final logit.
    *   **Attention Analysis**: Aggregates attention weights across layers to pinpoint focal words.
    *   **LLM Reasoner**: Synthesizes the top-k important features into a coherent English sentence explaining the prediction.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 5. System Architecture

```mermaid
graph TD
    A[Raw Text Input] --> B(Preprocessing & Tokenization)
    B --> C{Model Selection}
    
    subgraph "Model Backend"
        C -->|Deep Learning| D[LSTM Network]
        C -->|Transformer| E[DistilBERT]
        C -->|Generative| F[Gemini 1.5 Flash]
    end
    
    subgraph "Explainability Engine"
        E --> G[Attention Rollout]
        E --> H[SHAP Explainer]
        E --> I[LIME Surrogate]
        
        G --> J{Evidence Aggregation}
        H --> J
        I --> J
        
        J --> K[LLM Reasoner (Flan-T5)]
    end
    
    F --> L[Direct Prediction]
    K --> M[Final Output: Label + Explanation]
    D --> N[Class Probabilities]
    
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style K fill:#bbf,stroke:#333,stroke-width:2px
```

**Architecture Components:**
*   **Preprocessing**: Handles unicode normalization and regex-based cleaning.
*   **Model Backend**: Supports TensorFlow (LSTM) and PyTorch (DistilBERT) backends.
*   **Explainability Engine**: A dedicated module that probes the trained models to extract feature importance scores.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 6. Workflow

The operational workflow is designed for reproducibility:

1.  **Input**: User provides a sentence or batch of text.
2.  **Processing**: Text is cleaned and vectorized.
3.  **Inference**: The selected model predicts the emotion label and confidence score.
4.  **Interpretation**:
    *   **SHAP/LIME**: Runs perturbation analysis to assign importance scores.
    *   **Attention**: Extracts attention matrices from the last layer.
5.  **Synthesis**: An LLM (Flan-T5) takes the prediction and top keywords to generate a human-readable explanation.
6.  **Output**: Display of Label, Confidence, Heatmap/Keywords, and Natural Language Rationale.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 7. Folder Structure

```bash
ğŸ“¦ Emotion-Classification-XAI
â”œâ”€â”€ ğŸ“œ lstm_model.py           # Deep Learning Model (LSTM + GloVe/Embeddings)
â”œâ”€â”€ ğŸ“œ attention_analysis.py   # Transformer (DistilBERT) + Attention Rollout
â”œâ”€â”€ ğŸ“œ shap_analysis.py        # SHAP-based Feature Importance Analysis
â”œâ”€â”€ ğŸ“œ lime_analysis.py        # LIME-based Local Explanations
â”œâ”€â”€ ğŸ“œ llm_explainability.py   # Generative Explanations using Flan-T5
â”œâ”€â”€ ğŸ“œ gemini_pipeline.py      # Zero-shot/Few-shot Classification via Gemini API
â”œâ”€â”€ ğŸ“œ requirements.txt        # Python Dependencies
â”œâ”€â”€ ğŸ“œ README.md               # Project Documentation
â””â”€â”€ ğŸ“œ LICENSE                 # MIT License
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 8. Features

*   **Multi-Modal Classification**: Support for LSTM, BERT-based, and LLM-based classifiers.
*   **Hybrid XAI**: Combines gradient-based (Attention), perturbation-based (LIME), and game-theoretic (SHAP) explanations.
*   **Natural Language Explanations**: Automatically converts numerical feature importance into text explanations.
*   **Agentic Pipeline**: Code is structured using an Agent-based pattern for modularity and extensibility.
*   **visualization**: (Console-based for now) text highlighting of important words.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 9. Installation & Setup

### Prerequisites
*   Python 3.8+
*   Git

### Steps

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/Maryamm-2/Emotion-Classification-with-Explainable-AI-Techniques.git
    cd Emotion-Classification-with-Explainable-AI-Techniques
    ```

2.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Environment Setup (Optional for Gemini)**
    If using the `gemini_pipeline.py`, set your API key:
    ```bash
    export GEMINI_API_KEY="your_api_key_here"
    # Or on Windows PowerShell:
    # $env:GEMINI_API_KEY="your_api_key_here"
    ```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 10. Usage

### 1. Run Baseline (LSTM)
Train and evaluate the LSTM model:
```bash
python lstm_model.py
```

### 2. Generate SHAP Explanations
Analyze feature importance using Game Theory:
```bash
python shap_analysis.py
```

### 3. Run Generative Explanations
Get a full report with Natural Language reasoning:
```bash
python llm_explainability.py
```

### 4. Interactive Analysis
The scripts are designed to prompt for user input or process the test set automatically.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 11. Results / Outputs

### Performance Metrics (DistilBERT)
*   **Accuracy**: ~93% (on Test Set)
*   **F1-Score**: 0.92

### Sample Output (LLM Explainer)
> **Input**: "I feel so agitated and restless after the meeting."
>
> **Prediction**: *Anger* (Confidence: 98%)
>
> **Key Words**: *agitated, restless, meeting*
>
> **Explanation**: The text expresses *Anger* because the user explicitly mentions feeling agitated and restless, which are high-arousal negative states associated with frustration.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 12. Future Improvements

*   **UI Dashboard**: Develop a Streamlit or React frontend to visualize attention heatmaps interactively.
*   **Multimodal Support**: Extend the pipeline to analyze audio tone alongside text for richer emotion detection.
*   **Model Distillation**: Compress the DistilBERT model for mobile deployment without sacrificing explainability.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 13. License

This project is licensed under the **MIT License**. See the `LICENSE` file for details.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## 14. Author

**Maryam Haroon**  
*AI / Machine Learning Engineer | Data Scientist*

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/maryam-haroon-ba51b8287/)
